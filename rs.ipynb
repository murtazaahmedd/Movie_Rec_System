{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "from keras import layers\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load and preprocess data\n",
    "def load_and_preprocess_data():\n",
    "    movies = pd.read_csv('dataset/movies.csv')\n",
    "    ratings = pd.read_csv('dataset/ratings.csv')\n",
    "\n",
    "    user_ids = ratings[\"userId\"].unique().tolist()\n",
    "    userencoded = {x: i for i, x in enumerate(user_ids)}\n",
    "    user_rev = {i: x for i, x in enumerate(user_ids)}\n",
    "\n",
    "    movie_ids = ratings['movieId'].unique().tolist()\n",
    "    moviecoded = {x: i for i, x in enumerate(movie_ids)}\n",
    "    movie_rev = {i: x for i, x in enumerate(movie_ids)}\n",
    "\n",
    "    ratings['user'] = ratings['userId'].map(userencoded)\n",
    "    ratings['movie'] = ratings['movieId'].map(moviecoded)\n",
    "\n",
    "    ratings['rating'] = (ratings['rating'] - ratings['rating'].mean()) / ratings['rating'].std()\n",
    "    max_rating = max(ratings['rating'])\n",
    "    min_rating = min(ratings['rating'])\n",
    "    ratings['rating'] = ratings['rating'].apply(lambda x: (x - min_rating) / (max_rating - min_rating))\n",
    "\n",
    "    # One-hot encode the genres\n",
    "    genres = set()\n",
    "    for genre_list in movies['genres']:\n",
    "        genres.update(genre_list.split('|'))\n",
    "    genres = list(genres)\n",
    "\n",
    "    for genre in genres:\n",
    "        movies[genre] = movies['genres'].apply(lambda x: 1 if genre in x else 0)\n",
    "\n",
    "    x = ratings[['user', 'movie']].values\n",
    "    y = ratings['rating'].values\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.1, random_state=42)\n",
    "\n",
    "    return movies, ratings, x_train, x_val, y_train, y_val, userencoded, user_rev, moviecoded, movie_rev, genres\n",
    "\n",
    "movies, ratings, x_train, x_val, y_train, y_val, userencoded, user_rev, moviecoded, movie_rev, genres = load_and_preprocess_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(num_users, num_movies, embedding_size=100):\n",
    "    user_layer = layers.Input(shape=[1])\n",
    "    user_embedding = layers.Embedding(num_users, embedding_size, embeddings_initializer=\"he_normal\",\n",
    "                                       embeddings_regularizer=keras.regularizers.l2(1e-6))(user_layer)\n",
    "    user_vector = layers.Flatten()(user_embedding)\n",
    "\n",
    "    movie_layer = layers.Input(shape=[1])\n",
    "    movie_embedding = layers.Embedding(num_movies, embedding_size, embeddings_initializer=\"he_normal\",\n",
    "                                        embeddings_regularizer=keras.regularizers.l2(1e-6))(movie_layer)\n",
    "    movie_vector = layers.Flatten()(movie_embedding)\n",
    "\n",
    "    prod = layers.dot(inputs=[user_vector, movie_vector], axes=1)\n",
    "    dense1 = layers.Dense(200, activation='relu')(prod)\n",
    "    dense2 = layers.Dense(100, activation='relu')(dense1)\n",
    "    dropout = layers.Dropout(0.5)(dense2)\n",
    "    dense3 = layers.Dense(1, activation='relu')(dropout)\n",
    "\n",
    "    model = Model([user_layer, movie_layer], dense3)\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss=\"mean_squared_error\", metrics=[\"mean_absolute_error\"])\n",
    "    return model\n",
    "\n",
    "model = build_model(len(userencoded), len(moviecoded))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 18ms/step - loss: 0.0817 - mean_absolute_error: 0.2218 - val_loss: 0.0550 - val_mean_absolute_error: 0.1858\n",
      "Epoch 2/30\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 16ms/step - loss: 0.0511 - mean_absolute_error: 0.1755 - val_loss: 0.0425 - val_mean_absolute_error: 0.1576\n",
      "Epoch 3/30\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 16ms/step - loss: 0.0197 - mean_absolute_error: 0.1028 - val_loss: 0.0452 - val_mean_absolute_error: 0.1603\n",
      "Epoch 4/30\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 18ms/step - loss: 0.0118 - mean_absolute_error: 0.0756 - val_loss: 0.0460 - val_mean_absolute_error: 0.1609\n",
      "Epoch 5/30\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 17ms/step - loss: 0.0107 - mean_absolute_error: 0.0684 - val_loss: 0.0464 - val_mean_absolute_error: 0.1625\n",
      "Epoch 6/30\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 15ms/step - loss: 0.0101 - mean_absolute_error: 0.0647 - val_loss: 0.0472 - val_mean_absolute_error: 0.1635\n",
      "Epoch 7/30\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 13ms/step - loss: 0.0095 - mean_absolute_error: 0.0615 - val_loss: 0.0473 - val_mean_absolute_error: 0.1626\n",
      "Epoch 8/30\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - loss: 0.0093 - mean_absolute_error: 0.0598 - val_loss: 0.0476 - val_mean_absolute_error: 0.1626\n",
      "Epoch 9/30\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - loss: 0.0092 - mean_absolute_error: 0.0586 - val_loss: 0.0478 - val_mean_absolute_error: 0.1627\n",
      "Epoch 10/30\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - loss: 0.0091 - mean_absolute_error: 0.0576 - val_loss: 0.0475 - val_mean_absolute_error: 0.1629\n",
      "Epoch 11/30\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 13ms/step - loss: 0.0090 - mean_absolute_error: 0.0568 - val_loss: 0.0474 - val_mean_absolute_error: 0.1613\n",
      "Epoch 12/30\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 15ms/step - loss: 0.0090 - mean_absolute_error: 0.0565 - val_loss: 0.0478 - val_mean_absolute_error: 0.1621\n",
      "Epoch 13/30\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 15ms/step - loss: 0.0089 - mean_absolute_error: 0.0559 - val_loss: 0.0478 - val_mean_absolute_error: 0.1624\n",
      "Epoch 14/30\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 16ms/step - loss: 0.0089 - mean_absolute_error: 0.0558 - val_loss: 0.0473 - val_mean_absolute_error: 0.1613\n",
      "Epoch 15/30\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 17ms/step - loss: 0.0087 - mean_absolute_error: 0.0551 - val_loss: 0.0474 - val_mean_absolute_error: 0.1624\n",
      "Epoch 16/30\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 18ms/step - loss: 0.0087 - mean_absolute_error: 0.0547 - val_loss: 0.0472 - val_mean_absolute_error: 0.1615\n",
      "Epoch 17/30\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 18ms/step - loss: 0.0087 - mean_absolute_error: 0.0543 - val_loss: 0.0474 - val_mean_absolute_error: 0.1621\n",
      "Epoch 18/30\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 19ms/step - loss: 0.0087 - mean_absolute_error: 0.0548 - val_loss: 0.0474 - val_mean_absolute_error: 0.1609\n",
      "Epoch 19/30\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 19ms/step - loss: 0.0086 - mean_absolute_error: 0.0540 - val_loss: 0.0472 - val_mean_absolute_error: 0.1608\n",
      "Epoch 20/30\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 19ms/step - loss: 0.0086 - mean_absolute_error: 0.0540 - val_loss: 0.0475 - val_mean_absolute_error: 0.1614\n",
      "Epoch 21/30\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 19ms/step - loss: 0.0086 - mean_absolute_error: 0.0540 - val_loss: 0.0477 - val_mean_absolute_error: 0.1608\n",
      "Epoch 22/30\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 20ms/step - loss: 0.0086 - mean_absolute_error: 0.0541 - val_loss: 0.0475 - val_mean_absolute_error: 0.1614\n",
      "Epoch 23/30\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 20ms/step - loss: 0.0084 - mean_absolute_error: 0.0538 - val_loss: 0.0473 - val_mean_absolute_error: 0.1611\n",
      "Epoch 24/30\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 19ms/step - loss: 0.0084 - mean_absolute_error: 0.0534 - val_loss: 0.0473 - val_mean_absolute_error: 0.1608\n",
      "Epoch 25/30\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 19ms/step - loss: 0.0084 - mean_absolute_error: 0.0532 - val_loss: 0.0468 - val_mean_absolute_error: 0.1607\n",
      "Epoch 26/30\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 19ms/step - loss: 0.0085 - mean_absolute_error: 0.0535 - val_loss: 0.0471 - val_mean_absolute_error: 0.1611\n",
      "Epoch 27/30\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 19ms/step - loss: 0.0083 - mean_absolute_error: 0.0532 - val_loss: 0.0468 - val_mean_absolute_error: 0.1605\n",
      "Epoch 28/30\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 19ms/step - loss: 0.0083 - mean_absolute_error: 0.0532 - val_loss: 0.0471 - val_mean_absolute_error: 0.1607\n",
      "Epoch 29/30\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 19ms/step - loss: 0.0084 - mean_absolute_error: 0.0533 - val_loss: 0.0466 - val_mean_absolute_error: 0.1605\n",
      "Epoch 30/30\n",
      "\u001b[1m1418/1418\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 19ms/step - loss: 0.0083 - mean_absolute_error: 0.0534 - val_loss: 0.0471 - val_mean_absolute_error: 0.1607\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x25556f4f2f0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([x_train[:, 0], x_train[:, 1]], y_train, validation_data=([x_val[:, 0], x_val[:, 1]], y_val), \n",
    "          batch_size=64, epochs=30, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m316/316\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Mean Squared Error (MSE): 0.04404742292757607\n",
      "Mean Absolute Error (MAE): 0.16068166438512316\n",
      "R2 Score: 0.1918258202698746\n"
     ]
    }
   ],
   "source": [
    "# Predict on validation set\n",
    "y_pred = model.predict([x_val[:, 0], x_val[:, 1]])\n",
    "\n",
    "# Compute performance metrics\n",
    "mse = mean_squared_error(y_val, y_pred)\n",
    "mae = mean_absolute_error(y_val, y_pred)\n",
    "r2 = r2_score(y_val, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"R2 Score: {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save(\"movie_recommendation_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_movies(user_id, selected_genres, top_n=10):\n",
    "    if user_id not in userencoded:\n",
    "        return {\"error\": f\"User ID {user_id} not found.\"}\n",
    "\n",
    "    # Map the user ID to its encoded value\n",
    "    user_encoder = userencoded[user_id]\n",
    "    \n",
    "    # Get movies the user has already watched\n",
    "    movies_watched = ratings[ratings['user'] == user_encoder][['movieId', 'rating']]\n",
    "    \n",
    "    # Get movies that the user has liked (rating > 0.8)\n",
    "    liked_movies = movies_watched[movies_watched['rating'] > 0.8]\n",
    "    \n",
    "    # Get all movies that the user has not yet rated\n",
    "    movies_not_watched = movies[~movies[\"movieId\"].isin(movies_watched['movieId'])][\"movieId\"]\n",
    "    movies_not_watched = list(set(movies_not_watched).intersection(set(moviecoded.keys())))\n",
    "    \n",
    "    # Prepare user-movie pairs for predictions\n",
    "    user_movie_array = np.hstack(([[user_encoder]] * len(movies_not_watched), [[moviecoded[x]] for x in movies_not_watched]))\n",
    "\n",
    "    # Predict ratings for the movies that the user hasn't watched yet\n",
    "    predicted_ratings = model.predict([user_movie_array[:, 0], user_movie_array[:, 1]]).flatten()\n",
    "    \n",
    "    # Create a dictionary of predicted ratings for movies the user has not watched\n",
    "    predicted_ratings_dict = {movie_id: rating for movie_id, rating in zip(movies_not_watched, predicted_ratings)}\n",
    "\n",
    "    # Filter movies by selected genres (context-based filtering)\n",
    "    filtered_movies = movies[movies[selected_genres].sum(axis=1) > 0]\n",
    "    filtered_movie_ids = filtered_movies['movieId'].values\n",
    "    \n",
    "    # Create a dictionary of filtered predicted ratings\n",
    "    filtered_predicted_ratings = {movie_id: predicted_ratings_dict.get(movie_id, 0) for movie_id in filtered_movie_ids}\n",
    "\n",
    "    # Sort the filtered movies by predicted ratings in descending order\n",
    "    top_movies = sorted(filtered_predicted_ratings.items(), key=lambda x: x[1], reverse=True)[:top_n]\n",
    "\n",
    "    # Prepare the list of recommended movies\n",
    "    recommended = [{\"title\": movies[movies[\"movieId\"] == movie_id][\"title\"].values[0],\n",
    "                    \"genres\": movies[movies[\"movieId\"] == movie_id][\"genres\"].values[0]}\n",
    "                   for movie_id, _ in top_movies]\n",
    "\n",
    "    return recommended\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(userencoded, open('userencoded.pkl', 'wb'))\n",
    "pickle.dump(moviecoded, open('moviecoded.pkl', 'wb'))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
